---
title: "data.table_lasso"
author: "Wenjzh"
date: "12/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R using data.table and glmnet
### Preparing the Data

```{r dt, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# Libraries: ------------------------------------------------------------------
library(Hmisc)
library(data.table)
library(glmnet)
library(SASxport)
library(tidyverse)
library(kableExtra)

# read in the  data: -----------------------------------------------------------
## This data will be used in the question. 
url_base <- 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/'

demo_file <- '../DATA/DEMO_I.XPT'
if ( !file.exists(demo_file) ) {
  demo_url <- sprintf('%s/DEMO_I.XPT', url_base)
  demo <- sasxport.get(demo_url)
  write.xport(demo, file = demo_file)
} else {
  demo <- sasxport.get(demo_file)
}

dr1_file <- '../DATA/DR1TOT_I.XPT'
if ( !file.exists(dr1_file) ) {
  dr1_url <- sprintf('%s/DR1TOT_I.XPT', url_base)
  dr1 <- sasxport.get(dr1_url)
  write.xport(dr1, file = dr1_file)
} else {
  dr1 <- sasxport.get(dr1_file)
}

dr2_file <- '../DATA/DR2TOT_I.XPT'
if ( !file.exists(demo_file) ) {
  dr2_url <- sprintf('%s/DR2TOT_I.XPT', url_base)
  dr2 <- sasxport.get(dr2_url)
  write.xport(dr2, file = dr2_file)
} else {
  dr2 <- sasxport.get(dr2_file)
}

bpx_file <- '../DATA/BPX_I.XPT'
if ( !file.exists(bpx_file) ) {
  bpx_url <- sprintf('%s/BPX_I.XPT', url_base)
  bpx <- sasxport.get(bpx_url)
  write.xport(bpx, file = bpx_file)
} else {
  bpx <- sasxport.get(bpx_file)
}

dr1 <-as.data.table(dr1)
dr2 <-as.data.table(dr2)
demo <-as.data.table(demo)
bpx <-as.data.table(bpx)
```

First, we imported all the 2015 NHANES datasets into R as data.table. Then we chose variables, combined four data.tables into one and dropping all missing observations with missing value. Below is the code of data cleaning process.

```{r prepare, include=TRUE}
# Choose variables
dr1 = dr1[,.(seqn, dr1talco,dr1.320z,dr1tcaff,dr1tsodi, 
             dr1ttfat,dr1tsugr,dr1tiron,dr1tfibe,dr1tprot)] 
dr2 = dr2[,.(seqn, dr2talco,dr2.320z,dr2tcaff,dr2tsodi,
             dr2ttfat,dr2tsugr,dr2tiron,dr2tfibe,dr2tprot)]
demo = demo[,.(seqn = seqn, age = ridageyr, pir = indfmpir, gender = riagendr)]
bpx = bpx[,.(seqn = seqn, 
             # most people havn't test 4 so we just ignore it
             systolic = (bpxsy1+bpxsy2+bpxsy3)/3,
             diastolic = (bpxdi1+bpxdi2+bpxdi3)/3)][,
             diff:=systolic-diastolic
             ]

# Combine the four data tables and drop the missing values
mydata=dr1[dr2,on = 'seqn'][demo, , on = 'seqn'][bpx,,on = 'seqn'][,
          .(id = seqn, systolic, diastolic, diff, gender,
            alco = (dr1talco+dr2talco)/2, water = (dr1.320z+dr2.320z)/2, 
            caff = (dr1tcaff+dr2tcaff)/2, sodi = (dr1tsodi+dr2tsodi)/2, 
            fat = (dr1ttfat+dr2ttfat)/2, sugr = (dr1tsugr+dr2tsugr)/2, 
            iron = (dr1tiron+dr2tiron)/2, fibe = (dr1tfibe+dr2tfibe)/2, 
            prot = (dr1tprot+dr2tprot)/2)][! is.na(id) & ! is.na(systolic) &
            ! is.na(diastolic) & ! is.na(gender) & ! is.na(alco) &
            ! is.na(water) & ! is.na(caff) & ! is.na(sodi) & 
            ! is.na(fat) & ! is.na(sugr) & ! is.na(iron) &
            ! is.na(fibe) & ! is.na(prot), ]
```

### LASSO Using GLMNET
At first, we plan to use the "lars" package to do lasso, but we can not add penaly factor in lars. Thus, we chose to use the glmnet package instead. "cv.glmnet", "plot.cv.glmnet" and "glmnet" functions are utilized.

#### Response and Predictor Variables
Response variables are systolic blood pressure and the difference in blood pressures, which can reflect the health status of one's blood pressure. The predictor variables, though, needed to be standardized before they could be put into the model. Here is the code to standardize the predictor variables:
```{r normalize, echo = TRUE, results = "hide"}
# Normalize the nutrition predictors
mydata[,6:14] <- lapply(mydata[,6:14], function(x) c(scale(x)))

# Change gender 1/2 to 0.5/-0.5
mydata = mydata[, gender := fifelse(gender==1, 0.5, -0.5)]
```

Gender was turned from 1 for 'male' and 2 for 'female' into setting 'male' to 0.5 and 'female' to -0.5, which helped to interpret the meaning of the coefficients of the interaction terms.

#### Interaction Terms

Before doing the lasso process, we added the interaction terms between gender and nutrition predictors.
```{r interaction, echo = TRUE, results = "hide"}
mydata = mydata[, .(systolic, diff, gender,alco,water,caff,sodi,fat,sugr,iron,fibe,prot,
                    gender_alco = gender*alco,
                    gender_water = gender*water,
                    gender_caff = gender*caff,
                    gender_sodi = gender*sodi,
                    gender_fat = gender*fat,
                    gender_sugr = gender*sugr,
                    gender_iron = gender*iron,
                    gender_fibe = gender*fibe,
                    gender_prot = gender*prot)]
```


#### Penalty Weights

Because we're only interested in the selected interaction terms, we only want to set L1-norm penalties on the coefficients of the interaction terms. Thus, we set penalty weight = 1 for the interaction terms (ex. gender_alco) while not penalizing  the independent terms (ex. alco and gender) by setting penalty weight = 0. We would have a penalty factor of:

````{r penalize factor, echo = TRUE, results = "hide"}
# Only penalize the interaction terms
pnfc=c(rep(0,10),rep(1,9))
```

In our data.table, the first two columns are the response variables; the 3rd to 10th columns are independent predictors and 11th to 21st columns are the interaction terms.

#### Cross Validation

Using "cv.glmnet" to choose the lambda with minimum MSE. In general, little inflation of lambda did not cause dramatic differences in LASSO results.

```{r glmnet, echo = TRUE, results = "hide"}
# LASSO using glmnet package: alpha = 1 ---------------------------------------
mydata = as.matrix(mydata)

set.seed(000)
cv_syst = cv.glmnet(x=mydata[,3:21],y=mydata[,1], type.measure="mse", 
                    family="gaussian",penalty.factor=pnfc,alpha = 1)
lambda_syst = cv_syst$lambda.min

cv_diff = cv.glmnet(x=mydata[,3:21],y=mydata[,2], type.measure="mse",
                    family="gaussian", penalty.factor=pnfc,alpha = 1)
lambda_diff = cv_diff$lambda.min
```

However, there is one thing we have to pay attention to. From the plots, it is obvious that the curve id not convex, so if we get the lambda of the edge condition (in the first plot, it is the point around 0.2, which may also be chosen as the lambda with minimum MSE), the penalized coefficients will all be shrinked to 0, which is definitely not what we want. Thus, we avoid that by setting seed and choosing proper cross validation result.

Here is the CV plot to choose lambda for the systolic model:

```{r, echo = FALSE, out.width = '50%', fig.align='center'}
plot(cv_syst$lambda, cv_syst$cvm, ylab = "Mean standard error", xlab = "lambda",
     main = "Cross-validation for lambda in systolic pressure")
abline(v = cv_syst$lambda.min)
```

And here is the CV plot to choose lambda for the difference model:

```{r, echo = FALSE, out.width = '50%', fig.align='center'}
plot(cv_diff$lambda, cv_diff$cvm, ylab = "Mean standard error", xlab = "lambda",
     main = "Cross-validation for lambda in pressure difference")
abline(v = cv_diff$lambda.min)
```

Notes: Here Wenjing used "cv.glmnet" to realize the cross validation. She will update this using self-made cross validation function in the final version.

#### Modeling

After all that preparation work, here we applied the chosen labda and penalty factor into the glmnet function to achieve the goal of only penalizing interaction terms.

```{r model}
lars_syst = 
  glmnet(x=mydata[,3:21],y=mydata[,1], penalty.factor=pnfc, family="gaussian",
         lambda=lambda_syst, alpha = 1,nlambda=100)

lars_diff = 
  glmnet(x=mydata[,3:21],y=mydata[,2], penalty.factor=pnfc, family="gaussian",
         lambda=lambda_diff, alpha = 1,nlambda=100)
```

### Results
We only focus on the coefficients of the interaction terms. Here are the resulting coefficients combined from the two models. 

```{r collection, echo = FALSE}
# data collection
coef1 = coef(lars_syst)
coef2 = coef(lars_diff)
coef = cbind(coef1, coef2)
lambda = cbind(lambda_syst, lambda_diff)
rownames(lambda) = "lambda_min_mse"
coef = rbind(coef, lambda)
colnames(coef) = c("systolic", "difference")
coef_int = as.matrix(coef)[c(2,12:21),]
knitr::kable(coef_int, digits=3, caption = "Nutrition Influence on Blood Pressure Across Gender")%>%
  kable_styling(full_width = F)
```

Remember that gender = 0.5 representing male and -0.5 representing female. In our common sense, the propotion of men with hypertention are higher than that of women, which is also supported by our results: coefficients of gender in both model are negative.

In the first model within systolic pressure as response, the variables with the greatest difference between men and women are sodium, alcohol, and caffeine. We can see that men's systolic pressure is affected by alcohol and sodium, while women's blood pressure is affected by caffeine.In the second model within difference between systolic and diastolic pressure as response, the variables with the greatest difference between men and women are sodium, alcohol, fat, water, and caffeine. We can see that men's systolic pressure is more affected by sodium, alcohol and fat, while women's blood pressure is affected by caffeine and water.

To make a robust conclusion, we considered both models together. In conclusion, men's systolic pressure is more affected by sodium, alcohol, while women's blood pressure is affected by caffeine. This results may help people to get more ideas about how to prevent hypertension: men should be more careful about alcohol intaking and women should pay more attention to caffeine intaking.